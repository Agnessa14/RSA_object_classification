{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the correlations for each layer and create input RDMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the function to create filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileName(n_samples, name):\n",
    "    return name \\\n",
    "        + \"_{}_\".format(n_samples) \\\n",
    "        + \"_{}_\".format(model_name) \\\n",
    "        + \"_{}\".format(layer_name)   \\\n",
    "        + \".npy\"       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the model and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the np file containing the shape of the activations\n",
    "ROOT_PATH = '/mnt/raid/ni/agnessa/RSA/Objects/'\n",
    "layers_path = '/mnt/raid/ni/agnessa/RSA/layer_names'\n",
    "NR_OF_SAMPLES = 10000\n",
    "#load json file with the layers of interest \n",
    "model_name = 'densenet161'\n",
    "json_file_layers=os.path.join(layers_path,model_name + '_selected_layers.json')\n",
    "with open(json_file_layers, \"r\") as fd:\n",
    "    selected_layers = json.load(fd)\n",
    "layer_name =  selected_layers[0].get('layer') #change the index at each iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my version\n",
    "def correlationd_matrix(batch_size): #(list_of_activations, n) ,array_activations\n",
    "    file_name = os.path.join(ROOT_PATH+'activations/',getFileName(NR_OF_SAMPLES,'activations'))\n",
    "    act = np.load(file_name,mmap_mode='r') #mmap is used to access a part of the file \n",
    "    correlationd = np.zeros((NR_OF_SAMPLES,NR_OF_SAMPLES))\n",
    "    correlationd[:] = np.nan\n",
    "    num_batches = int(NR_OF_SAMPLES / batch_size)\n",
    "    total = sum(x+1 for x in range(num_batches)) #num 1000-wise comparisons to do: 55\n",
    "    index = 0\n",
    "   \n",
    "    for i in range(num_batches): #[0:9[\n",
    "        start_1 = batch_size*i\n",
    "        end_1 = batch_size*(i+1)\n",
    "        list_of_activations_1 = act[start_1:end_1,:]\n",
    "\n",
    "        for j in range(i,num_batches): #[i:10[\n",
    "            index += 1\n",
    "            print(\"New Iteration: i = {0}, j = {1}; {2}/{3}\".format(i,j,index,total))\n",
    "            start_2 = batch_size*(j)\n",
    "            end_2 = batch_size*(j+1)\n",
    "            list_of_activations_2 = act[start_2:end_2,:]\n",
    "            corr_activations = 1-np.corrcoef(list_of_activations_1,list_of_activations_2) #2000 x 2000 matrix\n",
    "\n",
    "            for x in range(corr_activations.shape[0]):\n",
    "                for y in range(corr_activations.shape[1]):\n",
    "                    if x < batch_size:\n",
    "                        start_x = start_1\n",
    "                    else: \n",
    "                        start_x = start_2-1000\n",
    "                    if y < batch_size:\n",
    "                        start_y = start_1\n",
    "                    else:\n",
    "                        start_y = start_2-1000                       \n",
    "                    correlationd[x+start_x,y+start_y] = correlationd[y+start_y,x+start_x] = corr_activations[x,y]\n",
    "\n",
    "    return(correlationd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#felix's method\n",
    "def correlationd_matrix(batch_size): #(list_of_activations, n) ,array_activations\n",
    "    file_name = os.path.join(ROOT_PATH+'activations/',getFileName(NR_OF_SAMPLES,'activations'))\n",
    "    act = np.load(file_name,mmap_mode='r') #mmap is used to access a part of the file \n",
    "    correlationd = np.zeros((NR_OF_SAMPLES,NR_OF_SAMPLES))\n",
    "    correlationd[:] = np.nan\n",
    "\n",
    "    extra_samples = (NR_OF_SAMPLES % batch_size) != 0\n",
    "    num_batches = int(NR_OF_SAMPLES / batch_size)\n",
    "    \n",
    "    total = sum(x+1 for x in range(num_batches)) #num 1000-wise comparisons to do: 55\n",
    "    index = 0\n",
    "\n",
    "    for i in range(num_batches):  # [0:9[\n",
    "        start_1 = batch_size * i\n",
    "        end_1 = batch_size * (i + 1)\n",
    "        list_of_activations_1 = act[start_1:end_1, :]\n",
    "        print(f\"loaded list of activations 1, shape: {list_of_activations_1.shape}\")\n",
    "\n",
    "        for j in range(i + 1, num_batches if not extra_samples else num_batches + 1):  # [i:10[\n",
    "            index += 1\n",
    "            print(\"New Iteration: i = {0}, j = {1}; {2}/{3}\".format(i, j, index, total))\n",
    "            start_2 = batch_size * j\n",
    "            if j == num_batches:\n",
    "                end_2 = NR_OF_SAMPLES\n",
    "            else:\n",
    "                end_2 = batch_size * (j + 1)\n",
    "\n",
    "            list_of_activations_2 = act[start_2:end_2, :]\n",
    "            print(f\"loaded list of activations 2, shape: {list_of_activations_2.shape}\")\n",
    "            # warnings.filterwarnings('error', message=\"invalid value encountered in true_divide\")\n",
    "            # try:\n",
    "            corr_activations = 1 - np.corrcoef(list_of_activations_1, list_of_activations_2)  # 2000 x 2000 matrix\n",
    "\n",
    "            # X times X correlation\n",
    "            if np.isnan(correlationd[start_1:end_1, start_1:end_1]).any():\n",
    "                print(\n",
    "                    f\"Adding X correlation in the {start_1}:{end_1}, {start_1}:{end_1} square with size {corr_activations[:batch_size, :batch_size].shape}\")\n",
    "                correlationd[start_1:end_1, start_1:end_1] = corr_activations[:batch_size, :batch_size]\n",
    "\n",
    "            # Y times Y correlation\n",
    "            if np.isnan(correlationd[start_2:end_2, start_2:end_2]).any():\n",
    "                print(\n",
    "                    f\"Adding Y correlation in the {start_2}:{end_2}, {start_2}:{end_2} square with size {corr_activations[batch_size:, batch_size:].shape}\")\n",
    "\n",
    "                correlationd[start_2:end_2, start_2:end_2] = corr_activations[batch_size:, batch_size:]\n",
    "            # X times Y correlation and vice versa\n",
    "\n",
    "            print(\n",
    "                f\"Adding XY correlation in the {start_1}:{end_1}, {start_2}:{end_2} square with size {corr_activations[batch_size:, :batch_size].shape}\")\n",
    "            correlationd[start_1:end_1, start_2:end_2] = corr_activations[:batch_size, batch_size:]\n",
    "            print(\n",
    "                f\"Adding YX correlation in the {start_2}:{end_2}, {start_1}:{end_1} square with size {corr_activations[batch_size:, :batch_size].T.shape}\")\n",
    "            correlationd[start_2:end_2, start_1:end_1] = corr_activations[:batch_size, batch_size:].T\n",
    "\n",
    "    return correlationd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the correlations for model:  densenet161 and layer:  features.denseblock1.denselayer1\n",
      "New Iteration: i = 0, j = 0; 1/55\n"
     ]
    }
   ],
   "source": [
    "print('Calculating the correlations for model: ',model_name,'and layer: ',layer_name)\n",
    "corr_matrix = correlationd_matrix(1000) \n",
    "path = os.path.join(ROOT_PATH + 'Input_RDM/', getFileName(NR_OF_SAMPLES, \"Input_RDM_\"))\n",
    "print(\"Save Input RDM -> {}\".format(path))\n",
    "np.save(path, np.array(corr_matrix)) \n",
    "fig = plt.figure(figsize=(17,15))\n",
    "ax = seaborn.heatmap(corr_matrix, cmap='rainbow', vmin=0.5, vmax=1.0)\n",
    "path_fig = os.path.join(ROOT_PATH + 'Input_RDM_plots', getFileName(NR_OF_SAMPLES,\"Input_RDM_\") + '.png')\n",
    "fig.savefig(path_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case the load function does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the load function gives an error, do this\n",
    "np_load_old = np.load # modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "activations_shape = np.load(path)\n",
    "np.load = np_load_old"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
