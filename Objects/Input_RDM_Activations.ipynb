{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5i6s2LZ5jp6"
   },
   "source": [
    "# Setup Environment\n",
    "Use validation set images from ILSVRC 2012 Challenge in a google drive folder with their labels in a meta.json. (Using validation set since no meta data available for test set)\n",
    "\n",
    "For more information see: http://image-net.org/challenges/LSVRC/2012/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IK1nFAS4h1GU"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import json\n",
    "import io\n",
    "import datetime\n",
    "import collections\n",
    "from skimage import io\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as tmodels\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.folder import default_loader \n",
    "from torchvision.models import *\n",
    "\n",
    "from scipy.stats.stats import pearsonr #maybe use this instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DFcMJrSgFtn"
   },
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "\n",
    "# replace with own directories\n",
    "imagenet_validation_path = '/mnt/raid/data/ni/dnn/ILSVRC2012_img_val'\n",
    "meta_file_path = '/mnt/raid/ni/agnessa/RSA/'\n",
    "ROOT_PATH = '/mnt/raid/ni/agnessa/RSA/'\n",
    "\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNfIlNxlYkCu"
   },
   "source": [
    "# Select Data and get Metadata\n",
    "Select 10 images of each of the 1000 classes of the validation data set together with their label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWEouppCfVr3"
   },
   "outputs": [],
   "source": [
    "class ILSVRCSubDataset(Dataset):\n",
    "    \"\"\"ILSVRC 2012 subset of the original val dataset\"\"\"\n",
    "\n",
    "    def __init__(self, json_file, root, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_file (string): Path to the json file with meta.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Parse META File\n",
    "        with open(json_file, \"r\") as fd:\n",
    "            self.meta = json.load(fd)\n",
    "        print(self.meta)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(self.root,\n",
    "                            self.meta[idx][\"0\"]) #merge root and the filename of the sample\n",
    "        sample = default_loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        wnid = self.meta[idx][\"1\"]\n",
    "            \n",
    "        return sample, wnid #sample, class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Mb9s-RYS6oUx",
    "outputId": "02d61293-ca9f-4359-e9da-48408738c425"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_val = ILSVRCSubDataset(json_file=os.path.join(meta_file_path,'meta.json'),\n",
    "                               root=imagenet_validation_path,\n",
    "                               transform=data_transforms)\n",
    "\n",
    "dataloaders = torch.utils.data.DataLoader(dataset_val, #Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "                                          batch_size=20, #how many samples per batch to load\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the activations from a layer for all samples and save them\n",
    "Use the subset with 10 images of 1000 classes on torchvisions pretrained models, get the activations of specific layers and calculate the Input RDM by correlating between the activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to create filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5dT1Ml13i12"
   },
   "outputs": [],
   "source": [
    "def getFileName(n_samples, name):\n",
    "    return name \\\n",
    "        + \"_{}_\".format(n_samples) \\\n",
    "        + \"_{}_\".format(model_name) \\\n",
    "        + \"_{}\".format(layer_name)  \\\n",
    "        + \".npy\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiwGbVIH2VKx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterator shouldn't be recreated every time, because it always returns the first element\n",
    "# Which breaks everything if shuffling is disabled\n",
    "\n",
    "#load json file with the layers of interest (resnets)\n",
    "json_file_layers=os.path.join(meta_file_path,'resnets_selected_layers.json')\n",
    "with open(json_file_layers, \"r\") as fd:\n",
    "    selected_layers = json.load(fd)#next index 20\n",
    "model_name, layer_name = selected_layers[57].get('model'),  selected_layers[57].get('layer') #change the index at each iteration\n",
    "model = eval( model_name+'(pretrained=True)')\n",
    "\n",
    "# #if you need to look up the index of a specific model\n",
    "# for idx, dictionary in enumerate(selected_layers):\n",
    "#     if dictionary.get('model') == 'resnet50':\n",
    "#         print(idx)\n",
    "#         break\n",
    "        \n",
    "NR_OF_SAMPLES = 10000 #num classes*num samples per class;  len(dataset_val)   \n",
    "batch_size = 20\n",
    "\n",
    "#important: put model in evaluation mode for consistent results\n",
    "model.eval()\n",
    "for layer,m in model.named_modules():\n",
    "    if layer == layer_name:\n",
    "        print('Getting activations for model->',model_name,'and layer->', layer_name)       \n",
    "        data_iterator = iter(dataloaders) #create an iterator for each layer\n",
    "        activations = list() \n",
    "        #arguments: model, input, output. every time that an output is computed, this hook is called and the lambda is executed\n",
    "        handle = m.register_forward_hook(lambda m, i, o: activations.append(list(o.data.numpy().squeeze()))) \n",
    "\n",
    "        for i in range(int(NR_OF_SAMPLES/batch_size)): #for each batch get the activations\n",
    "            print(\".\", end='')\n",
    "            cur = next(data_iterator)[0] #cur: images, labels             \n",
    "            out = model(cur) #probabilities of each class? or output of each layer ie activations?\n",
    "\n",
    "        print('Model->',model_name,'and layer->',layer_name,': done.')\n",
    "            \n",
    "        flattened = np.array(activations).reshape(NR_OF_SAMPLES,-1)\n",
    "        print(\"Shape of the flattened activations -> \",flattened.shape)\n",
    "\n",
    "        #save activations \n",
    "        path = os.path.join(ROOT_PATH + 'activations/', getFileName(NR_OF_SAMPLES,\"activations\"))\n",
    "        print(\"Save Activation -> {}\".format(path))\n",
    "\n",
    "        np.save(path, flattened)\n",
    "\n",
    "        #clear variables\n",
    "        del(activations)\n",
    "        del(data_iterator)\n",
    "        handle.remove() #remove hook\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RSA_on_ImageNet_calculate_input_RDM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
