{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5i6s2LZ5jp6"
   },
   "source": [
    "# Setup Environment\n",
    "Use validation set images from ILSVRC 2012 Challenge in a google drive folder with their labels in a meta.json. (Using validation set since no meta data available for test set)\n",
    "\n",
    "For more information see: http://image-net.org/challenges/LSVRC/2012/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IK1nFAS4h1GU"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import default_loader\n",
    "import json\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as tmodels\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import *\n",
    "import numpy as np\n",
    "os.environ['TORCH_HOME'] = '/mnt/raid/ni/agnessa/RSA/.cache/torch/' #directory where pretrained models are saved\n",
    "imagenet_validation_path = '/mnt/raid/data/ni/dnn/ILSVRC2012_img_val'\n",
    "meta_file_path = '/mnt/raid/ni/agnessa/RSA/'\n",
    "layers_path = '/mnt/raid/ni/agnessa/RSA/layer_names'\n",
    "ROOT_PATH = '/mnt/raid/ni/agnessa/RSA/Objects/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNfIlNxlYkCu"
   },
   "source": [
    "# Select Data and get Metadata\n",
    "Select 10 images of each of the 1000 classes of the validation data set together with their label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWEouppCfVr3"
   },
   "outputs": [],
   "source": [
    "class ILSVRCSubDataset(Dataset):\n",
    "    \"\"\"ILSVRC 2012 subset of the original val dataset\"\"\"\n",
    "\n",
    "    def __init__(self, json_file, root, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_file (string): Path to the json file with meta.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Parse META File\n",
    "        with open(json_file, \"r\") as fd:\n",
    "            self.meta = json.load(fd)\n",
    "        print(self.meta)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(self.root,\n",
    "                            self.meta[idx][\"0\"]) #merge root and the filename of the sample\n",
    "        sample = default_loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        wnid = self.meta[idx][\"1\"]\n",
    "            \n",
    "        return sample, wnid #sample, class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Mb9s-RYS6oUx",
    "outputId": "02d61293-ca9f-4359-e9da-48408738c425"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_val = ILSVRCSubDataset(json_file=os.path.join(meta_file_path,'meta.json'),\n",
    "                               root=imagenet_validation_path,\n",
    "                               transform=data_transforms)\n",
    "\n",
    "dataloaders = torch.utils.data.DataLoader(dataset_val, #Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "                                          batch_size=1, #how many samples per batch to load\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the activations from a layer for all samples and save them\n",
    "Use the subset with 10 images of 1000 classes on torchvisions pretrained models, get the activations of specific layers and calculate the Input RDM by correlating between the activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to create filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5dT1Ml13i12"
   },
   "outputs": [],
   "source": [
    "def getFileName(n_samples, name):\n",
    "    return name \\\n",
    "        + \"_{}_\".format(n_samples) \\\n",
    "        + \"_{}_\".format(model_name) \\\n",
    "        + \"_{}\".format(layer_name)  \\\n",
    "        + \".npy\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiwGbVIH2VKx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterator shouldn't be recreated every time, because it always returns the first element\n",
    "# Which breaks everything if shuffling is disabled\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#load json file with the layers of interest \n",
    "model_name = 'vgg16'\n",
    "json_file_layers=os.path.join(layers_path,model_name + '_selected_layers.json')\n",
    "with open(json_file_layers, \"r\") as fd:\n",
    "    selected_layers = json.load(fd)\n",
    "\n",
    "model = eval( model_name+'(pretrained=True)')\n",
    "NR_OF_SAMPLES = 1 #num classes*num samples per class;  len(dataset_val)   \n",
    "batch_size = 1\n",
    "\n",
    "#important: put model in evaluation mode for consistent results\n",
    "model.eval()\n",
    "hooks = list()\n",
    "\n",
    "for layer,m in model.named_modules():\n",
    "    data_iterator = iter(dataloaders) #create an iterator for each layer\n",
    "    activations = list() \n",
    "    m.auto_name = layer\n",
    "    handle = m.register_forward_hook(lambda m, i, o: print(f\"Hook called from: {m.auto_name}\\n Input dimension: {i[0].size()} \\n Output dimension: {o.shape} \\n ############################\")\n",
    "    )\n",
    "    hooks.append(handle)\n",
    "    \n",
    "    for i in range(int(NR_OF_SAMPLES/batch_size)): #for each batch get the activations\n",
    "        print(\".\", end='')\n",
    "        cur = next(data_iterator)[0] #cur: images, labels             \n",
    "        out = model(cur) #probabilities of each class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RSA_on_ImageNet_calculate_input_RDM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
