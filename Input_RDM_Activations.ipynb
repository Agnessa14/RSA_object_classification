{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5i6s2LZ5jp6"
   },
   "source": [
    "# Setup Environment\n",
    "Use validation set images from ILSVRC 2012 Challenge in a google drive folder with their labels in a meta.json. (Using validation set since no meta data available for test set)\n",
    "\n",
    "For more information see: http://image-net.org/challenges/LSVRC/2012/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IK1nFAS4h1GU"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import json\n",
    "import io\n",
    "import datetime\n",
    "import collections\n",
    "from skimage import io\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import tables\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as tmodels\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.folder import default_loader \n",
    "from torchvision.models import *\n",
    "\n",
    "from scipy.stats.stats import pearsonr #maybe use this instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DFcMJrSgFtn"
   },
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "\n",
    "# replace with own directories\n",
    "imagenet_validation_path = '/mnt/raid/data/ni/dnn/ILSVRC2012_img_val'\n",
    "meta_file_path = '/mnt/raid/ni/agnessa/RSA/'\n",
    "ROOT_PATH = '/mnt/raid/ni/agnessa/RSA/'\n",
    "\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNfIlNxlYkCu"
   },
   "source": [
    "# Select Data and get Metadata\n",
    "Select 10 images of each of the 1000 classes of the validation data set together with their label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWEouppCfVr3"
   },
   "outputs": [],
   "source": [
    "class ILSVRCSubDataset(Dataset):\n",
    "    \"\"\"ILSVRC 2012 subset of the original val dataset\"\"\"\n",
    "\n",
    "    def __init__(self, json_file, root, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_file (string): Path to the json file with meta.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Parse META File\n",
    "        with open(json_file, \"r\") as fd:\n",
    "            self.meta = json.load(fd)\n",
    "        print(self.meta)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(self.root,\n",
    "                            self.meta[idx][\"0\"]) #merge root and the filename of the sample\n",
    "        sample = default_loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        wnid = self.meta[idx][\"1\"]\n",
    "            \n",
    "        return sample, wnid #sample, class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Mb9s-RYS6oUx",
    "outputId": "02d61293-ca9f-4359-e9da-48408738c425"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_val = ILSVRCSubDataset(json_file=os.path.join(meta_file_path,'meta.json'),\n",
    "                               root=imagenet_validation_path,\n",
    "                               transform=data_transforms)\n",
    "\n",
    "dataloaders = torch.utils.data.DataLoader(dataset_val, #Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "                                          batch_size=20, #how many samples per batch to load\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6itIYM2e5w_7"
   },
   "source": [
    "# Get model and activations\n",
    "Use the subset with 10 images of 1000 classes on torchvisions pretrained models, get the activations of specific layers and calculate the Input RDM by correlating between the activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5dT1Ml13i12"
   },
   "outputs": [],
   "source": [
    "def getFileName(n_samples, name):\n",
    "    return name \\\n",
    "        + \"_{}_\".format(n_samples) \\\n",
    "        + \"_{}_\".format(model_name) \\\n",
    "        + \"_{}\".format(layer_name)  \\\n",
    "        + \".npy\"\n",
    "#         + datetime.datetime.now().replace(microsecond=0).isoformat() \\\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNameh5(n_samples, name):\n",
    "    return name \\\n",
    "        + \"_{}_\".format(n_samples) \\\n",
    "        + \"_{}_\".format(model_name) \\\n",
    "        + \"_{}\".format(layer_name)  \\\n",
    "        + \".h5\"\n",
    "#         + datetime.datetime.now().replace(microsecond=0).isoformat() \\\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the activations from a layer for all samples, save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiwGbVIH2VKx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterator shouldn't be recreated every time, because it always returns the first element\n",
    "# Which breaks everything if shuffling is disabled\n",
    "\n",
    "#load json file with the layers of interest (resnets)\n",
    "json_file_layers=os.path.join(meta_file_path,'resnets_selected_layers.json')\n",
    "with open(json_file_layers, \"r\") as fd:\n",
    "    selected_layers = json.load(fd)#next index 20\n",
    "model_name, layer_name = selected_layers[17].get('model'),  selected_layers[17].get('layer') #change the index at each iteration\n",
    "print(model_name+'(pretrained=True)')\n",
    "model = eval( model_name+'(pretrained=True)')\n",
    "\n",
    "# #if you need to look up the index of a specific model\n",
    "# for idx, dictionary in enumerate(selected_layers):\n",
    "#     if dictionary.get('model') == 'resnet50':\n",
    "#         print(idx)\n",
    "#         break\n",
    "        \n",
    "NR_OF_SAMPLES = 10000 #num classes*num samples per class;  len(dataset_val)   \n",
    "batch_size = 20\n",
    "\n",
    "#important: put model in evaluation mode for consistent results\n",
    "model.eval()\n",
    "print('Getting activations for model->',model_name,'and layer->', layer_name)\n",
    "for layer,m in model.named_modules():\n",
    "    if layer == layer_name:\n",
    "        #create an iterator for each layer\n",
    "        data_iterator = iter(dataloaders) \n",
    "        activations = list() \n",
    "        handle = m.register_forward_hook(lambda m, i, o: activations.append(list(o.data.numpy().squeeze()))) \n",
    "        #arguments: model, input, output. every time that an output is computed, this hook is called and the lambda is executed\n",
    "\n",
    "        #for each batch get the activations for each batch\n",
    "        for i in range(int(NR_OF_SAMPLES/batch_size)): \n",
    "            print(\".\", end='')\n",
    "            cur = next(data_iterator)[0] #cur: images, labels             \n",
    "            out = model(cur) #probabilities of each class\n",
    "\n",
    "#prepare for flattening over features\n",
    "print('size activations->',np.array(activations).shape)\n",
    "\n",
    "#flatten into num samples x num features\n",
    "flattened = np.array(activations).reshape(NR_OF_SAMPLES,-1)\n",
    "print(flattened.shape)\n",
    "\n",
    "#save activations  \n",
    "path = os.path.join(ROOT_PATH + 'activations/', getFileName(NR_OF_SAMPLES,\"activations\"))\n",
    "print(\"Save Activation -> {}\".format(path))\n",
    "np.save(path, flattened)\n",
    "#clear variables\n",
    "handle.remove() #remove hook\n",
    "del(activations)\n",
    "del(data_iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case you need to run only one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for layer 1\n",
    "\n",
    "# # Iterator shouldn't be recreated every time, because it always returns the first element\n",
    "# # Which breaks everything if shuffling is disabled\n",
    "# # data_iterator = iter(dataloaders)\n",
    "# model_name = 'resnet34'\n",
    "# layer_name = 'layer1.0'\n",
    "# NR_OF_SAMPLES = 10000 #num classes*num samples/class;  len(dataset_val) \n",
    "# batch_size = 20\n",
    "\n",
    "# path = os.path.join(ROOT_PATH + 'activations/', getFileName(NR_OF_SAMPLES,\"activations\"))\n",
    "# # save np.load\n",
    "# np_load_old = np.load\n",
    "\n",
    "# # modify the default parameters of np.load\n",
    "# np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "# activations = np.load(path)\n",
    "# np.load = np_load_old\n",
    "\n",
    "# #correlation matrix = input RDM\n",
    "# y = activations.shape[2]\n",
    "# x = activations.shape[3]\n",
    "# w = activations.shape[4]\n",
    "\n",
    "# print('size activations->',np.array(activations).shape)\n",
    "# print('y,x,w->',y,x,w)\n",
    "\n",
    "# flattened = np.array(activations).reshape(NR_OF_SAMPLES,y*x*w)\n",
    "# corr_matrix = correlationd_matrix(flattened,NR_OF_SAMPLES) \n",
    "# path = os.path.join(ROOT_PATH + 'Input_RDM/', getFileName(NR_OF_SAMPLES, \"Input_RDM\"))\n",
    "# print(\"Save Input RDM ->len {}\".format(path))\n",
    "# np.save(path, np.array(corr_matrix))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RSA_on_ImageNet_calculate_input_RDM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
